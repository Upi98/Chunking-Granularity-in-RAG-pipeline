---

## ðŸ“œ License

This project is licensed under License - see the [LICENSE](LICENSE) file for details.

# Advanced Path-Based RAG Evaluation Framework
This project provides a complete, end-to-end pipeline for evaluating the effectiveness of different text chunking strategies within a sophisticated Path-Based Retrieval-Augmented Generation (RAG) system. It demonstrates how to move beyond simple vector search by leveraging a Neo4j Knowledge Graph.

The workflow ingests documents, creates a graph of interconnected text chunks and entities, and then evaluates retrieval performance by traversing these connections to build a richer, more relevant context for a Large Language Model (LLM).

# ðŸ—ï¸ **Architectural Overview**
The project follows a multi-stage workflow designed to build and evaluate a Graph RAG system. The key innovation is in the final evaluation step, which uses graph traversals for context retrieval.

# ðŸ“„ **Data Ingestion (main.py):** 
PDF documents are parsed to extract raw text content. Metadata is extracted from the filenames.

# ðŸ”ª **Multi-Strategy Chunking (main.py):** 
The text is processed in parallel by multiple chunking algorithms, including fixed-size, sentence-aware, and a custom structure-aware hybrid method. The hybrid method also extracts structural metadata like headings.

# ðŸ§  **Embedding (embedding_processor.py):** 
Chunks are converted into dense vector embeddings using a SentenceTransformer model.

# ðŸ’¾ **Initial Graph Storage (neo4j_storage.py):** 
Chunks, embeddings, and metadata are stored as (Document)-[:CONTAINS]->(Chunk) nodes in Neo4j.

# âœ¨ **Graph Enrichment & Path Creation (enrich_graph_spacy.py):** 
This critical step transforms the simple document graph into a rich, interconnected knowledge graph. It traverses the stored chunks and:

Creates :NEXT_CHUNK relationships to link sequential text chunks.

Uses spaCy for Named Entity Recognition (NER) to create new Company, Metric, and Segment nodes.

Creates :MENTIONS relationships from chunks to the entities they reference.

# ðŸ“ˆ **Path-Based RAG Evaluation (batch_naive_rag_eval.py):** 

This is the core evaluation loop, which tests the effectiveness of the graph structure.

**1. Load Questions:** A Q&A dataset is loaded from evaluation_qa.csv.

**2. Find Anchors:** For a given question, it performs a vector search to find the most relevant "anchor" chunks. The chunking method being tested acts as a filter for this initial search.

**3. Traverse Paths:** From each anchor chunk, it traverses the graph, following :NEXT_CHUNK and :MENTIONS relationships to gather surrounding context and related entities.

**4. Construct Context:** A rich context is built for the LLM, combining the anchor chunk's text with preceding/following text snippets and a list of mentioned entities.

**5. Generate & Evaluate:** The question and the path-based context are sent to a local LLM. The generated answer is then compared against the ground-truth answer using a full suite of metrics.

# âœ¨ **Key Features**
**Path-Based Graph RAG:** Moves beyond simple k-NN search by traversing the knowledge graph to build a more comprehensive and contextually aware prompt.

**Multi-Strategy Chunking:** Systematically creates and evaluates nodes generated by fixed, sentence-aware, and a custom hybrid chunking method.

**Automated Graph Enrichment:** Uses spaCy to automatically identify and link named entities, creating the relational paths necessary for advanced retrieval.

**Sequential Context Awareness:** Explicitly links sequential chunks (:NEXT_CHUNK), allowing the RAG system to retrieve preceding and succeeding context for any relevant chunk.

**Comprehensive Evaluation Suite:** Calculates BLEU, ROUGE-1/2/L, F1-Score, Semantic Similarity, and Exact Match to provide a holistic view of performance.

**Local & Private:** Designed to work with local models (SentenceTransformers, Ollama), ensuring data privacy and cost control.

**Modular & Configurable:** Easily configured via a .env file and composed of distinct, single-purpose scripts.

# ðŸ”§ **Core Components**

**File	Description**
**main.py**	Ingestion Orchestrator. Manages PDF extraction, chunking, embedding, and initial storage in Neo4j.

**pdf_extractor.py**	Extracts raw text from PDF files.

**chunking.py**	Implementations for fixed-size, sentence-aware, and hybrid chunking strategies.

**embedding_processor.py**	Handles loading the embedding model and generating vectors.

**neo4j_storage.py**	Manages writing chunk data to Neo4j, including document nodes and chunk properties.

**enrich_graph_spacy.py**	Required for Path RAG. Enriches the graph with entity nodes and creates :NEXT_CHUNK and :MENTIONS relationships.

**batch_naive_rag_eval.py**	Main Evaluation Script. Runs the full Path-Based RAG evaluation using the graph structure.

**evaluation_qa.csv** The input CSV file containing questions and ground-truth answers for the evaluation loop.

# ðŸš€ **Getting Started**

**Neo4j Database:** An active Neo4j instance (v5.x recommended). You need the URI, username, and password. The APOC plugin is required.

**Local LLM Server:** An Ollama instance running a model like mistral:7b-instruct-v0.3-q4_K_M.

**Source Documents:** Your PDF files placed in a data/ directory at the project root.

# **Installation**
**Clone the repository:**

git clone <your-repository-url>
cd <your-repository-name>

**Create and activate a virtual environment:**

python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

**Install the required Python packages from requirements.txt:**

pip install -r requirements.txt

A requirements.txt for this project would include:

**requirements.txt**
pandas
numpy
neo4j
python-dotenv
requests
spacy>=3.0
sentence-transformers
transformers
nltk
rouge-score
scikit-learn
PyPDF2
tiktoken

**Download the spaCy model:**

python -m spacy download en_core_web_lg

**Environment Configuration**

Create a .env file in the project's root directory and populate it with your credentials.

**Neo4j Connection Details**

NEO4J_URI="bolt://localhost:7687"

NEO4J_USERNAME="neo4j"

NEO4J_PASSWORD="your_neo4j_password"

NEO4J_DATABASE="neo4j"

**Local LLM (Ollama) API Endpoint**

LOCAL_LLM_API_URL="http://localhost:11434/api/chat"

LOCAL_LLM_REQUEST_TIMEOUT=240

**Embedding model to filter by during enrichment/evaluation**

EMBEDDING_MODEL_FILTER="sentence-transformers/multi-qa-mpnet-base-cos-v1"

# **âš™ï¸ How to Run the Pipeline**

Execute these scripts sequentially from the src/ directory.

**Step 1: Ingest and Chunk Documents**
This script reads PDFs, applies all chunking strategies, and stores the base (Document)-[:CONTAINS]->(Chunk) structure in Neo4j.

cd src
python main.py

**Step 2: Enrich Graph and Build Paths**
This script is mandatory for the Path RAG evaluation. It creates the :NEXT_CHUNK and :MENTIONS relationships that the evaluation script will traverse.

python enrich_graph_spacy_optimized.py

**Step 3: Run the Path-Based RAG Evaluation**
This is the final step. It uses the evaluation_qa.csv file to test the performance of the Path RAG system, using each chunking method as a different starting point for anchor selection.

Note: This process is computationally intensive and can take a significant amount of time.

python batch_naive_rag_eval.py

The script will generate detailed logs and results in the results/ directory, including the final report final_chunking_path_rag_all_metrics.csv.

**ðŸ“Š Evaluation Metrics**
The evaluation script measures performance using a comprehensive set of metrics to compare the LLM's generated answer against the ground-truth answer:

**F1 Score:** The harmonic mean of token-level precision and recall.

**ROUGE-1/2/L:** Measures the overlap of unigrams, bigrams, and the longest common subsequence, respectively.

**BLEU:** Measures n-gram precision, penalizing answers that are too short.

**Semantic Similarity:** The cosine similarity between the vector embeddings of the generated and ground-truth answers.








